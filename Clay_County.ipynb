{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Working Code For all Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CODE FOR LOGIN\"\"\"\n",
    "def login():\n",
    "    try:\n",
    "        driver.get(\"https://landmark.clayclerk.com/LandmarkWeb/Home/Index\")\n",
    "        time.sleep(6)   \n",
    "        driver.find_element_by_xpath('//*[@id=\"bodySection\"]/div/div/div[2]/div/div[7]/a/img').click() #records img\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath('//*[@id=\"idAcceptYes\"]').click() #ACCEPT\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath('//*[@id=\"lastNumOfDays-RecordDate\"]/option[2]').click() #Last 7 Days\n",
    "        driver.find_element_by_xpath('//*[@id=\"submit-RecordDate\"]').click() #SUBMIT\n",
    "        time.sleep(30)\n",
    "        driver.find_element_by_xpath('//*[@id=\"resultsTable\"]/thead/tr[1]/th[9]/label/input').click()#DocType Click\n",
    "        driver.find_element_by_xpath('//*[@id=\"resultsTable\"]/thead/tr[1]/th[9]/label/input').send_keys(\"mortgage\")#DocType edit\n",
    "        time.sleep(25)\n",
    "    except Exception as e:\n",
    "        print(\"Login Error... Run Code Again = \",e)\n",
    "        \n",
    "        \n",
    "\"\"\"FOR CLICK ON PRINT BUTTTON AND AUTO DOWNLOAD PDF\"\"\" \n",
    "def print_click_download():\n",
    "    try:\n",
    "        time.sleep(20)\n",
    "        driver.find_element_by_xpath('//*[@id=\"idPrintGroup\"]').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"DocumentPrintButtonAll\"]/a').click()\n",
    "        time.sleep(10)\n",
    "        driver.switch_to.alert.accept()\n",
    "        time.sleep(25)\n",
    "        time.sleep(20)\n",
    "        PDFadd()     \n",
    "        time.sleep(4)\n",
    "        driver.find_element_by_xpath('//*[@id=\"returnToSearchButton\"]').click()\n",
    "    except Exception as e:\n",
    "        print(\"Error at download PDF = \",e)\n",
    "        comp_address.append(\"NAF\")\n",
    "\n",
    "        \n",
    "\"\"\"CODE FOR PDF address extraction\"\"\"\n",
    "def PDFadd():\n",
    "\n",
    "    try:\n",
    "        #os.path.isfile(os.path.join(\"C:\\\\Users\\\\Dishant\\\\Downloads\\\\\", \"Landmark Web Official Records Search.pdf\")) \n",
    "        filename = os.path.join(\"C:\\\\Users\\\\Dishant\\\\Downloads\\\\\", \"Landmark Web Official Records Search.pdf\")        \n",
    "        pages = convert_from_path(filename, 500)\n",
    "        print(\"\\nNumber of Pages found in PDF = \",len(pages))\n",
    "        trials=0\n",
    "        start = \"\"\n",
    "        end = \"\"\n",
    "        found = False\n",
    "        for page in pages:\n",
    "            add=\"\"\n",
    "            page.save('C:\\\\Users\\\\Dishant\\\\Downloads\\\\add_img.jpg', 'JPEG')\n",
    "            address_txt = str(((pytesseract.image_to_string(Image.open('C:\\\\Users\\\\Dishant\\\\Downloads\\\\add_img.jpg'))))).lower()\n",
    "            #print(property_value)\n",
    "            try:\n",
    "            \n",
    "                try:\n",
    "\n",
    "                    start = re.search('which currently has the address of\\s', address_txt).span()\n",
    "                    end = re.search(\"together\\swith\\sall\",address_txt).span()\n",
    "                    add = address_txt[start[1]:end[0]]\n",
    "                    demo = add.split(\",\")\n",
    "                    plot_street = demo[0]\n",
    "                    city = demo[1]\n",
    "                    state_pin = re.search(\"florida\\s\\d{5}\",demo[2]).group()\n",
    "                    print(\"Address Found : \\t\",add)\n",
    "                    print(plot_street+\"|\"+city+\"|\"+state_pin)\n",
    "                    add = plot_street+\"|\"+city+\"|\"+state_pin\n",
    "                    comp_address.append(add)\n",
    "                    trials+=1\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "\n",
    "                    start = re.search('which currently has the address of\\s', address_txt).span()\n",
    "                    end = re.search('\\(\\\"property\\\\s\\\\naddress\\\"\\)',address_txt).span()\n",
    "                    add = address_txt[start[1]:end[0]]\n",
    "                    demo = add.split(\",\")\n",
    "                    plot_street = demo[0]\n",
    "                    city = demo[1]\n",
    "                    state_pin = re.search(\"florida\\s\\d{5}\",demo[2]).group()\n",
    "                    print(\"Exception Address Found : \\t\",add)\n",
    "                    print(plot_street+\"|\"+city+\"|\"+state_pin)\n",
    "                    add = plot_street+\"|\"+city+\"|\"+state_pin\n",
    "                    comp_address.append(add)\n",
    "                    print(e)          \n",
    "                    trials+=1\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"For Loop Exception\",e)\n",
    "                trials+=1\n",
    "                \n",
    "            time.sleep(2)\n",
    "            if(trials == 4):\n",
    "                break\n",
    "            \n",
    "        if(add==\"\"):\n",
    "            comp_address.append(\"NAF\")\n",
    "        file_upload_API()\n",
    "        os.remove('C:\\\\Users\\\\Dishant\\\\Downloads\\\\add_img.jpg')\n",
    "        os.remove(filename)\n",
    "    except Exception as e:\n",
    "        comp_address.append(\"NAF\")\n",
    "        print(\"Error at end PDFadd() \",e)\n",
    "\n",
    "\n",
    "\"\"\"FOR GOING TO WESITE FOR PROPERTY VALUE\"\"\"\n",
    "def prop_val():\n",
    "    try:\n",
    "        driver.get(\"http://www.totalviewrealestate.com/\")  \n",
    "        time.sleep(7)   \n",
    "        driver.find_element_by_xpath('//*[@id=\"header\"]/form/p/input[1]').send_keys(Address) \n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_xpath('//*[@id=\"header\"]/form/p/input[2]').send_keys(City) \n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_xpath('//*[@id=\"header\"]/form/p/input[3]').send_keys(pin) \n",
    "        driver.find_element_by_xpath('//*[@id=\"header\"]/form/input').click() #SUBMIT\n",
    "        time.sleep(15)\n",
    "        data = driver.find_element_by_xpath('//*[@id=\"leftpi\"]/p[2]').text\n",
    "        print(data)\n",
    "        lis.append(data)\n",
    "        time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(\"Error at pop_val() = \",e)\n",
    "        lis.append(\"NAF\")\n",
    "\n",
    "\"\"\"FOR CLAIM VALUE CONVERTING TO INTEGER\"\"\"\n",
    "def claim_val_converter(string_value):\n",
    "    C_Value = \"\"\n",
    "    try:\n",
    "        for i in string_value.split(\".\")[0]: \n",
    "            if(i.isdigit()):\n",
    "\n",
    "                C_Value = C_Value + i\n",
    "        return int(C_Value)\n",
    "    except Exception as e:\n",
    "        C_Value = \"NA\"\n",
    "        return C_Value\n",
    "    \n",
    "\n",
    "\"\"\"FOR HIGH VALUATION VALUE\"\"\"\n",
    "def HVVF():\n",
    "    high_value = \"\"\n",
    "    for i in HVS: \n",
    "        if(i.isdigit()):\n",
    "            high_value = high_value + i\n",
    "    return high_value\n",
    "\n",
    "\"\"\"FOR LOW VALUATION VALUE\"\"\"\n",
    "def LVVF():\n",
    "    low_value = \"\"\n",
    "    for i in LVS: \n",
    "        if(i.isdigit()):\n",
    "            low_value = low_value + i\n",
    "    return low_value\n",
    "        \n",
    "        \n",
    "\"\"\"CODE FOR API\"\"\"\n",
    "def file_upload_API():\n",
    "    try:\n",
    "        file_upload_url = \"https://brokerapi.cravingcode.in/api/UploadCountyDocument\"\n",
    "        File_name = os.path.join(\"C:\\\\Users\\\\Dishant\\\\Downloads\\\\\", \"Landmark Web Official Records Search.pdf\")\n",
    "        files = {\"uploadedFile\": open(File_name, 'rb')}\n",
    "        jsondata = {\"apiKey\": \"1FhWHQfB8v3sEMZIp2tZ1aCOXDKmLtNRjphO8MRXbfG6RuNWrA7yxyQd2YcU9FDrMIYDagUd095QSDfS5VsijA==\"}\n",
    "        response = requests.post(file_upload_url, files=files, data=jsondata)\n",
    "        response = json.loads(response.text)\n",
    "        print(response)\n",
    "        files[\"uploadedFile\"].close()\n",
    "        link = response['Message']\n",
    "        doc_link.append(link)\n",
    "    except Exception as e:\n",
    "        print(\"Error at file_upload_API() = \",e)\n",
    "        doc_link.append(\"Failed To Upload\")\n",
    "        \n",
    "##########################################################\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "from pdf2image import convert_from_path\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from PIL import Image \n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "import pyautogui\n",
    "import requests\n",
    "import random\n",
    "import PyPDF2 \n",
    "import json\n",
    "import mouse\n",
    "import time \n",
    "import os\n",
    "import re\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "base_dir = os.path.abspath(os.path.dirname(\"__file__\"))\n",
    "\n",
    "# Different Proxys : =    192.41.71.199:3128   50.246.120.125:8080     \n",
    "PROXY = \"192.41.71.221:3128\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "appState = {\n",
    "    \"recentDestinations\": [\n",
    "        {\n",
    "            \"id\": \"Save as PDF\",\n",
    "            \"origin\": \"local\",\n",
    "            \"account\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"selectedDestinationId\": \"Save as PDF\",\n",
    "    \"version\": 2\n",
    "}\n",
    "profile = {'printing.print_preview_sticky_settings.appState': json.dumps(appState)}\n",
    "\n",
    "options.add_experimental_option('prefs',  {\n",
    "    \"download.default_directory\": base_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"plugins.always_open_pdf_externally\": True\n",
    "    }\n",
    ")\n",
    "options.headless = False \n",
    "options.add_argument('--proxy-server=%s' % PROXY)\n",
    "options.add_experimental_option('prefs', profile)\n",
    "options.add_argument('--kiosk-printing')\n",
    "path = \"C:\\\\Users\\\\Dishant\\\\Desktop\\\\chromedriver\\\\chromedriver\"\n",
    "\n",
    "global driver , pdfno , comp_address , lis , doc_link\n",
    "lis=[]\n",
    "doc_link=[]\n",
    "comp_address = []\n",
    "driver = webdriver.Chrome(executable_path = path , options = options)\n",
    "\n",
    "# to save data into lists\n",
    "bank_name = []\n",
    "def_name = []\n",
    "real_value = []\n",
    "doc_type = []\n",
    "case_date = [] \n",
    "case_no = []\n",
    "\n",
    "login()   #Function Calling\n",
    "\n",
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "#To check total number of cases found in mortgage  \n",
    "items=0 \n",
    "for a in soup.findAll('td', attrs={'class':'tablecell nowordbreak sorting_1'}):\n",
    "    #print(a.text)\n",
    "    items+=1\n",
    "print(\"Total number of cases in MORTGAGE = \",items)\n",
    "time.sleep(5)\n",
    "\n",
    "# to scrape data out of each file\n",
    "try:\n",
    "    for i in range(items):\n",
    "        javaScript = 'document.getElementsByClassName(\"tablecell nowordbreak sorting_1\")['+str(i)+'].click();'\n",
    "        driver.execute_script(javaScript)\n",
    "        time.sleep(10)\n",
    "\n",
    "        cn = driver.find_element_by_xpath('//*[@id=\"documentInformationParent\"]/table/tbody/tr[1]/td[2]').text\n",
    "        if(cn==\"\"):\n",
    "            case_no.append(\"0\")\n",
    "        else:\n",
    "            case_no.append(cn)\n",
    "\n",
    "        cd = driver.find_element_by_xpath('//*[@id=\"documentInformationParent\"]/table/tbody/tr[5]/td[2]').text\n",
    "        if(cd==\"\"):\n",
    "            case_date.append(\"0\")\n",
    "        else:\n",
    "            case_date.append(cd.split(\" \")[0])\n",
    "\n",
    "        d_t = driver.find_element_by_xpath('//*[@id=\"documentInformationParent\"]/table/tbody/tr[10]/td[2]').text\n",
    "        if(d_t==\"\"):\n",
    "            doc_type.append(\"0\")\n",
    "        else:\n",
    "            doc_type.append(d_t)\n",
    "\n",
    "        c_v = driver.find_element_by_xpath('//*[@id=\"documentInformationParent\"]/table/tbody/tr[14]/td[2]').text\n",
    "        if(c_v==\"\"):\n",
    "            real_value.append(\"0\")\n",
    "        else:\n",
    "            real_value.append(c_v)\n",
    "\n",
    "        def_n = driver.find_element_by_xpath('//*[@id=\"documentInformationParent\"]/table/tbody/tr[16]/td[2]').text\n",
    "        if(def_n==\"\"):\n",
    "            def_name.append(\"0\")\n",
    "        else:\n",
    "            def_name.append(def_n.replace(\"\\n\",\" and \"))\n",
    "\n",
    "        b_n = driver.find_element_by_xpath('//*[@id=\"documentInformationParent\"]/table/tbody/tr[18]/td[2]').text\n",
    "        if(b_n==\"\"):\n",
    "            bank_name.append(\"0\")\n",
    "        else:\n",
    "            try:\n",
    "                bank_name.append(b_n.split(\"\\n\")[1])\n",
    "            except Exception as e:\n",
    "                print(\"Exception at Bank Name = \",e)\n",
    "                bank_name.append(b_n)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        #To download PDF and take out address\n",
    "        print_click_download()\n",
    "except Exception as e:\n",
    "    print(\"Main Program for loop  =  \",e)\n",
    "    case_no.append(\"0\")\n",
    "    case_date.append(\"0\")\n",
    "    doc_type.append(\"0\")\n",
    "    real_value.append(\"0\")\n",
    "    def_name.append(\"0\")\n",
    "    bank_name.append(\"0\")\n",
    "    comp_address.append(\"NAF\")\n",
    "    doc_link.append(\"0\")\n",
    "\n",
    "        \n",
    "    \n",
    "#To check weather all the entries are of same lenght\n",
    "if(len(case_date)==items and len(case_no)==items and len(bank_name)==items and len(def_name)==items and \n",
    "   len(doc_type)==items and len(real_value)==items):\n",
    "    print(\"SUCCESS\") \n",
    "else:\n",
    "    print(\"Check the Code Once...!!\")\n",
    "\n",
    "\n",
    "#To make DataFrame and save it as a CSV file    \n",
    "Case_Data = pd.DataFrame({'CaseId':case_no,'CaseDate':case_date,'CaseType':doc_type,'BankName':bank_name,'DefendentName':def_name,\n",
    "                          'RealValueString':real_value,'Trial Address':comp_address})\n",
    "Case_Data.to_csv('Case_Data.csv', index = False , encoding='utf-8')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "\"\"\"STARTING 2nd PHASE\"\"\"\n",
    "list_HVS = []\n",
    "list_HVV = []\n",
    "list_LVS = []\n",
    "list_LVV = []\n",
    "    \n",
    "for i in range(len(comp_address)):\n",
    "    print(comp_address[i])\n",
    "    if(comp_address[i]==\"NAF\"):\n",
    "        lis.append(\"NAF\")\n",
    "        continue\n",
    "    else:\n",
    "        demo = comp_address[i].split(\"|\")\n",
    "        Address = demo[0]\n",
    "        City = demo[1]\n",
    "        pin = demo[2].split(\" \")[1]\n",
    "        print(Address,City,pin)\n",
    "        prop_val1()\n",
    "driver.close()\n",
    "\n",
    "\n",
    "\"\"\" FOR EXTRACTING HIGH LOW VALUE OF PROPRERTY \"\"\"\n",
    "for i in range(len(lis)):\n",
    "    demo = lis[i]\n",
    "    if(demo == \"NAF\"):\n",
    "        HVS = \"NA\"\n",
    "        HVV = \"NA\"\n",
    "        LVS = \"NA\"\n",
    "        LVV = \"NA\"\n",
    "        print(\"\\n\")\n",
    "        print(\"Low Value String = \",LVS)\n",
    "        print(\"Low Value = \",LVV)\n",
    "        print(\"High Value String = \",HVS)\n",
    "        print(\"High Value = \",HVV)\n",
    "        list_HVS.append(HVS)\n",
    "        list_HVV.append(HVV)\n",
    "        list_LVS.append(LVS)\n",
    "        list_LVV.append(LVV)\n",
    "    else:\n",
    "        #print(demo)\n",
    "        start = re.search(\"Value\\sRange\",demo).span()\n",
    "        #print(start)\n",
    "        end = re.search(\"Change\\:\\s\",demo).span()\n",
    "        #print(end)\n",
    "        got = demo[start[1]:end[0]]\n",
    "        got.split(\"to\")\n",
    "        HVS = got.split(\"to\")[1].split(\"\\n\")[0]\n",
    "        HVV = HVVF()\n",
    "        LVS = got.split(\"to\")[0].split(\" \")[1]\n",
    "        LVV = LVVF()\n",
    "        print(\"\\n\")\n",
    "        print(\"Low Value String = \",LVS)\n",
    "        print(\"Low Value = \",LVV)\n",
    "        print(\"High Value String = \",HVS)\n",
    "        print(\"High Value = \",HVV)\n",
    "        list_HVS.append(HVS)\n",
    "        list_HVV.append(int(HVV))\n",
    "        list_LVS.append(LVS)\n",
    "        list_LVV.append(int(LVV))\n",
    "\n",
    "\n",
    "\"\"\"FOR GETTING CLAIM VALUE FROM DATASET\"\"\"\n",
    "base_dir = os.path.abspath(os.path.dirname(\"__file__\"))\n",
    "dataset = pd.read_csv(base_dir+\"\\\\Case_Data.csv\")\n",
    "got_str_values = dataset[\"RealValueString\"]\n",
    "new_int_real_value = []\n",
    "for i in range(len(got_str_values)):\n",
    "    got_int_value = claim_val_converter(got_str_values[i])\n",
    "    new_int_real_value.append(got_int_value)\n",
    "    #print(got_int_value)\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"FOR CALCULATIONS\"\"\"\n",
    "Avg_App_V_L=[]\n",
    "Avg_Est_V_L = []\n",
    "Acq_Ratio_L = []\n",
    "\n",
    "\n",
    "for i in range(len(new_int_real_value)):\n",
    "    real_value = new_int_real_value[i]\n",
    "    high = list_HVV[i]\n",
    "    #print(high)\n",
    "    low = list_LVV[i]\n",
    "    #print(low)\n",
    "    if(high==\"NA\" or low == \"NA\"):\n",
    "        Avg_App_V = \"NA\"   \n",
    "        Avg_App_V_L.append(Avg_App_V) #Average Approximate Value\n",
    "        Avg_Est_V = \"NA\" \n",
    "        Avg_Est_V_L.append(Avg_Est_V) #Average Estimated Value\n",
    "        Acq_Ratio = \"NA\"\n",
    "        Acq_Ratio_L.append(Acq_Ratio) #Acquisation Ratio\n",
    "    else:\n",
    "        Avg_App_V = (high+low)/2   \n",
    "        Avg_App_V_L.append(Avg_App_V) #Average Approximate Value\n",
    "        Avg_Est_V = Avg_App_V - real_value \n",
    "        Avg_Est_V_L.append(Avg_Est_V) #Average Estimated Value\n",
    "        Acq_Ratio = (real_value / Avg_App_V) * 100\n",
    "        Acq_Ratio_L.append(Acq_Ratio) #Acquisation Ratio\n",
    "        \n",
    "\n",
    "        \n",
    "\"\"\"DATE CHANGE TO DD/MM/YYYY FORMAT\"\"\"\n",
    "ncd=[]\n",
    "for i in dataset[\"CaseDate\"]:\n",
    "    try:\n",
    "        n_x = i.split(\"/\")\n",
    "        date = n_x[1]+\"/\"+n_x[0]+\"/\"+n_x[2]\n",
    "        ncd.append(date)\n",
    "    except Exception as e:\n",
    "        print(\"Error at Date Change\\t\",e)\n",
    "        ncd.append(\"0\")\n",
    "        \n",
    "\n",
    "        \n",
    "\"\"\"ADDING AQUIRED DATA TO DATAFRAME\"\"\"\n",
    "address = []\n",
    "city = []\n",
    "zipcode  = []\n",
    "county_name = []\n",
    "RV=[]\n",
    "dt=[]\n",
    "for i in dataset['RealValueString']: RV.append(i.replace(\"$\",\"\"))\n",
    "for x in range(len(comp_address)): county_name.append(\"Clay\")\n",
    "for x in range(len(dataset['DefendentName'])): dt.append(\"0\")\n",
    "#Sperating Trial_Address Fiels\n",
    "for i in range(len(dataset[\"Trial Address\"])):\n",
    "    if(dataset[\"Trial Address\"][i]==\"NAF\"):\n",
    "        address.append(\"NAF\")\n",
    "        city.append(\"NAF\")\n",
    "        zipcode.append(\"NAF\")        \n",
    "    else:\n",
    "        a=dataset[\"Trial Address\"][i]\n",
    "        x=a.split(\"|\")\n",
    "        address.append(x[0])\n",
    "        city.append(x[1])\n",
    "        zipcode.append(\"FL \" + x[2].split(\" \")[1])\n",
    "        \n",
    "    \n",
    "del dataset['Trial Address'] #Deleting Trial_Address Coloumn\n",
    "del dataset['CaseDate'] #Deleting Case Date old\n",
    "dataset.insert(loc=1, column='CaseDate', value=ncd) #Add casedate dd/mm/yy\n",
    "dataset.insert(loc=5, column='DefendentType', value = dt)\n",
    "dataset.insert(loc=7, column='RealValue', value = RV) #Add RealValue\n",
    "dataset['Address'] = address\n",
    "dataset['City'] = city\n",
    "dataset['Zipcode'] = zipcode\n",
    "dataset['HighValuationString'] = list_HVS\n",
    "dataset['HighValuationValue'] = list_HVV\n",
    "dataset['LowValuationString'] = list_LVS\n",
    "dataset['LowValuationValue'] = list_LVV\n",
    "dataset['AverageApproximateValue'] = Avg_App_V_L\n",
    "dataset['AverageEstimateValue'] = Avg_Est_V_L\n",
    "dataset['AcquisitionRatio'] = Acq_Ratio_L\n",
    "dataset['CountyName'] = county_name\n",
    "# last_shift = dataset[\"DocumentLink\"] #shifting document links to last\n",
    "# del dataset[\"DocumentLink\"] #deleting old documnet links\n",
    "# dataset[\"DocumentLink\"] = last_shift #adding new documnet links\n",
    "dataset.to_csv('Clay County Data.csv')   # Final CSV File...\n",
    "print(dataset)\n",
    "\n",
    "os.remove(\"Case_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TO GET CURRENT FOLDER PATH \"\"\"\n",
    "import os\n",
    "base_dir = os.path.abspath(os.path.dirname(\"__file__\"))\n",
    "PROJECT_ROOT = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "BASE_DIR = os.path.dirname(\"__file__\")\n",
    "print(base_dir)\n",
    "print(PROJECT_ROOT)\n",
    "print(BASE_DIR)\n",
    "print(os.path.realpath(\"__file__\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=\"ABCDE\"\n",
    "for i in range(5):\n",
    "    print(s1)\n",
    "    s1=s1[1:]+s1[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
